{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c304f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggested imports. Do not use import any modules that are not in the requirements.txt file on the VLE.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98e8ff",
   "metadata": {},
   "source": [
    "# Movie titles assignment\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "* [Data filtering and splitting (10%)](#Data-filtering-and-splitting-(10%))\n",
    "* [Title classification (25%)](#Title-classification-(25%))\n",
    "* [Title generation (25%)](#Title-generation-(25%))\n",
    "* [Language models as classifiers (30%)](#Language-models-as-classifiers-(30%))\n",
    "* [Conclusion (10%)](#Conclusion-(10%))\n",
    "\n",
    "Information:\n",
    "\n",
    "This assignment is 100% of your assessment.\n",
    "You are to follow the instructions below and fill each cell as instructed.\n",
    "Once ready, submit this notebook on VLE with all the outputs included (run all your code and don't clear any output cells).\n",
    "Do not submit anything else apart from the notebook and do not use any extra data apart from what is requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab5373",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A big shot Hollywood producer is looking for a way to automatically generate new movie titles for future movies and you have been employed to do this (in exchange for millions of dollars!).\n",
    "A data set of movie details has already been collected from IMDb for you and your task is to create the model and the algorithms necessary to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb2f45",
   "metadata": {},
   "source": [
    "## Data filtering and splitting (10%)\n",
    "\n",
    "Start by downloading the CSV file `filmtv_movies - ENG.csv` from [this kaggle data set](https://www.kaggle.com/datasets/stefanoleone992/filmtv-movies-dataset).\n",
    "\n",
    "The CSV file needs to be filtered as the producer is only interested in certain types of movie titles.\n",
    "Load the file and filter it so that only movies with the following criteria are kept:\n",
    "\n",
    "* The country needs to be `United States` (and no other country should be mentioned).\n",
    "* The genre should be `Action`, `Horror`, `Fantasy`, `Western`, and `Adventure`.\n",
    "* The title should not have more than 20 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de60b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/filmtv_movies - ENG.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2a2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['Action', 'Horror', 'Fantasy', 'Western', 'Adventure']\n",
    "\n",
    "data = data.loc[(data['country'] == 'United States') &\n",
    "                (data['genre'].isin(genres)) & \n",
    "                (data['title'].str.len() <= 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448acbaa",
   "metadata": {},
   "source": [
    "Split the filtered data into 80% train, 10% validation, and 10% test.\n",
    "You will only need the title and genre columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1fca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['title', 'genre']]\n",
    "train, validate, test = np.split(data.sample(frac=1), [int(.8*len(data)), int(.9*len(data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d5332",
   "metadata": {},
   "source": [
    "From your processed data set, display:\n",
    "\n",
    "* the amount of movies in each genre and split\n",
    "* 5 examples of movie titles from each genre and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e8adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 2736\n",
      "Validation Set Size: 342\n",
      "Test Set Size: 342\n",
      "Num. of movies with genre Horror: 926 \n",
      "Num. of movies with genre Action: 914 \n",
      "Num. of movies with genre Western: 538 \n",
      "Num. of movies with genre Adventure: 483 \n",
      "Num. of movies with genre Fantasy: 559 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Set Size: {len(train)}\")\n",
    "print(f\"Validation Set Size: {len(validate)}\")\n",
    "print(f\"Test Set Size: {len(test)}\")\n",
    "\n",
    "for genre in data['genre'].unique():\n",
    "    print(f\"Num. of movies with genre {genre}: {len(data[data['genre'] == genre])} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1240be",
   "metadata": {},
   "source": [
    "## Title classification (25%)\n",
    "\n",
    "Your first task is to prove that a neural network can identify the genre of a movie based on its title.\n",
    "\n",
    "You will note that many titles are just a single word or two words long so you need to work at the character level instead of the word level, that is, a token would be a single character, including punctuation marks and spaces.\n",
    "You must also lowercase the titles.\n",
    "Preprocess the data sets, create a neural network, and train it to classify the movie titles into their genre.\n",
    "Plot a graph of the **accuracy** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7522adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title'] = train['title'].str.lower()\n",
    "titles_temp = train['title'].values\n",
    "titles = [list(title) for title in titles_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e94d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8b60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "train_x = []\n",
    "train_y = []\n",
    "for row in range(0, len(train)):\n",
    "    title = list(train.iloc[row]['title'].lower())\n",
    "    genre = [train.iloc[row]['genre']]\n",
    "\n",
    "    train_x.append(title)\n",
    "    train_y.append(genre)\n",
    "\n",
    "# Testing Set\n",
    "test_x = []\n",
    "test_y = []\n",
    "for row in range(0, len(test)):\n",
    "    title = list(test.iloc[row]['title'].lower())\n",
    "    genre = [test.iloc[row]['genre']]\n",
    "\n",
    "    test_x.append(title)\n",
    "    test_y.append(genre)\n",
    "\n",
    "# Lengths\n",
    "train_lens = torch.tensor(\n",
    "    [len(title) for title in train_x],\n",
    "    dtype=torch.int64, device=device\n",
    ")\n",
    "\n",
    "test_lens = torch.tensor(\n",
    "    [len(title) for title in test_x],\n",
    "    dtype=torch.int64, device=device\n",
    ")\n",
    "\n",
    "max_len = max(max(train_lens), max(test_lens))\n",
    "\n",
    "# Genres\n",
    "genre = sorted(set(genre for text in train_y for genre in text))\n",
    "genre = sorted(genre)\n",
    "\n",
    "# Genre Indexing\n",
    "genre2index = {genre: i for (i, genre) in enumerate(genre)}\n",
    "\n",
    "# vocab\n",
    "frequencies = collections.Counter(letter for text in train_x for word in text for letter in word)\n",
    "vocab = sorted(frequencies.keys(), key=frequencies.get, reverse=True)\n",
    "while frequencies[vocab[-1]] < min_freq:\n",
    "    vocab.pop()\n",
    "vocab = ['<PAD>', '<UNK>'] + sorted(vocab)\n",
    "letter2index = {letter: i for (i, letter) in enumerate(vocab)}\n",
    "\n",
    "# Padding and UNK indexing\n",
    "for i in range(len(train_x)):\n",
    "    for j in range(len(train_x[i])):\n",
    "        if train_x[i][j] not in letter2index:\n",
    "            train_x[i][j] = '<UNK>'\n",
    "    \n",
    "    for x in range(0, (max_len - len(train_x[i]))):\n",
    "        train_x[i].extend(['<PAD>'])\n",
    "    \n",
    "    temp_ans = train_y[i]\n",
    "    train_y[i] = [0] * len(genre)\n",
    "    train_y[i][genre2index[temp_ans[0]]] = 1\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    for j in range(len(test_x[i])):\n",
    "        if test_x[i][j] not in letter2index:\n",
    "            test_x[i][j] = '<UNK>'\n",
    "\n",
    "    for x in range(0, (max_len - len(test_x[i]))):\n",
    "        test_x[i].extend(['<PAD>'])\n",
    "    \n",
    "    temp_ans = test_y[i]\n",
    "    test_y[i] = [0] * len(genre)\n",
    "    test_y[i][genre2index[temp_ans[0]]] = 1\n",
    "\n",
    "# indexing\n",
    "indexed_train_x = torch.tensor([[letter2index[letter] for letter in text] for text in train_x], \n",
    "                                dtype=torch.int64, \n",
    "                                device=device)\n",
    "indexed_train_y = torch.tensor([y for y in train_y],\n",
    "                                dtype=torch.float32, \n",
    "                                device=device)\n",
    "\n",
    "indexed_test_x = torch.tensor([[letter2index[letter] for letter in text] for text in test_x], \n",
    "                                dtype=torch.int64, \n",
    "                                device=device)\n",
    "indexed_test_y = torch.tensor([y for y in test_y],\n",
    "                                dtype=torch.float32, \n",
    "                                device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e49ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 vocab: ['<PAD>', '<UNK>', ' ', '!', '&', \"'\", ',', '-', '.', '/']\n",
      "Last 10 vocab: ['q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Vocab Size: 47\n",
      "\n",
      "First train_x:\n",
      " ['a', 'm', 'u', 's', 'e', 'm', 'e', 'n', 't', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "First train_y: [0, 0, 0, 1, 0]\n",
      "\n",
      "Genres: ['Action', 'Adventure', 'Fantasy', 'Horror', 'Western']\n",
      "\n",
      "First indexed_train_x:\n",
      " tensor([40, 28, 25,  2, 29, 34, 34, 31, 25, 25, 36, 25, 38, 39,  0,  0,  0,  0,\n",
      "         0,  0])\n",
      "First indexed_train_y:\n",
      " tensor([0., 0., 0., 1., 0.])\n",
      "\n",
      "First indexed_test_x:\n",
      " tensor([43, 21, 38, 38, 29, 35, 38,  2, 21, 34, 27, 25, 32, 39,  0,  0,  0,  0,\n",
      "         0,  0])\n",
      "First indexed_test_y:\n",
      " tensor([1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(f'First 10 vocab: {vocab[:10]}')\n",
    "print(f'Last 10 vocab: {vocab[-10:]}')\n",
    "print(f'Vocab Size: {len(vocab)}\\n')\n",
    "\n",
    "print(f'First train_x:\\n {train_x[1]}\\n')\n",
    "print(f'First train_y: {train_y[0]}\\n')\n",
    "\n",
    "print(f'Genres: {genre}\\n')\n",
    "\n",
    "print(f'First indexed_train_x:\\n {indexed_train_x[0]}')\n",
    "print(f'First indexed_train_y:\\n {indexed_train_y[0]}\\n')\n",
    "\n",
    "print(f'First indexed_test_x:\\n {indexed_test_x[0]}')\n",
    "print(f'First indexed_test_y:\\n {indexed_test_y[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6041f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, chars_size, embedding_size, hidden_size, genre_size, max_len):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = torch.nn.Embedding(chars_size, embedding_size)\n",
    "        self.output_layer = torch.nn.Linear(max_len*hidden_size, genre_size) # Output size number of genres\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden = self.embedding_layer(x)\n",
    "        flattened = torch.flatten(hidden, 1, 2)\n",
    "        return self.output_layer(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "969fec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreClassifier():\n",
    "    \n",
    "    def __init__(self, chars, iters, title_lens, genre_size, embedding, hidden, max_len):\n",
    "        self.model = Model(chars_size=len(chars), embedding_size=embedding, hidden_size=hidden, genre_size=genre_size, max_len=max_len)\n",
    "        self.model.to(device)\n",
    "        self.optimiser = torch.optim.Adam(self.model.parameters())\n",
    "\n",
    "        self.iters = iters\n",
    "        self.title_lens = title_lens\n",
    "        self.train_errors = []\n",
    "    \n",
    "    def run(self, indexed_train_x, indexed_train_y):\n",
    "        print('step', 'error')\n",
    "        self.train_errors = []\n",
    "\n",
    "        for step in range(1, self.iters + 1):  \n",
    "            self.optimiser.zero_grad()\n",
    "            output = self.model(indexed_train_x)\n",
    "            error = torch.nn.functional.binary_cross_entropy_with_logits(output, indexed_train_y)\n",
    "            self.train_errors.append(error.detach().tolist())\n",
    "            error.backward()\n",
    "            self.optimiser.step()\n",
    "\n",
    "            if step%100 == 0:\n",
    "                print(step, self.train_errors[-1])  \n",
    "\n",
    "        \n",
    "        \n",
    "    def accuracy(self, test_x, test_y):\n",
    "        with torch.no_grad():\n",
    "            predictions = torch.sigmoid(self.model(test_x))\n",
    "            accuracy = (torch.round(predictions) == test_y).numpy().mean()\n",
    "            print('Test accuracy: {:.3%}'.format(accuracy))\n",
    "    \n",
    "    def f1_score(self, test_x, test_y):\n",
    "        with torch.no_grad():\n",
    "            predictions = torch.sigmoid(self.model(test_x))\n",
    "            f1 = sklearn.metrics.f1_score(test_y, predictions,)\n",
    "\n",
    "    def errors(self):\n",
    "        (fig, ax) = plt.subplots(1, 1)\n",
    "        ax.set_xlabel('step')\n",
    "        ax.set_ylabel('$E$')\n",
    "        ax.plot(range(1, len(self.train_errors) + 1), self.train_errors, color='blue', linestyle='-', linewidth=3)\n",
    "        ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7f5db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step error\n",
      "100 0.43730300664901733\n",
      "200 0.41310131549835205\n",
      "300 0.3972942531108856\n",
      "400 0.38493281602859497\n",
      "500 0.37475818395614624\n",
      "600 0.36621564626693726\n",
      "700 0.35902139544487\n",
      "800 0.35292506217956543\n",
      "900 0.34768247604370117\n",
      "1000 0.3431324362754822\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = GenreClassifier(chars=vocab, iters=1000, title_lens=train_lens, genre_size=len(genre), embedding=32, hidden=32, max_len=max_len)\n",
    "classifier.run(indexed_train_x, indexed_train_y)\n",
    "classifier.errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cb755a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 75.380%\n"
     ]
    }
   ],
   "source": [
    "classifier.accuracy(indexed_test_x, indexed_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53265d7",
   "metadata": {},
   "source": [
    "Measure the F1 score performance of the model when applied on the test set.\n",
    "Also plot a confusion matrix showing how often each genre is mistaken as another genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e9f69c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\University of Malta\\BSC 3.1\\Deep Learning for NPL\\Assignment\\movie_titles.ipynb Cell 21\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/University%20of%20Malta/BSC%203.1/Deep%20Learning%20for%20NPL/Assignment/movie_titles.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mf1_score(indexed_test_x, indexed_test_y)\n",
      "\u001b[1;32me:\\University of Malta\\BSC 3.1\\Deep Learning for NPL\\Assignment\\movie_titles.ipynb Cell 21\u001b[0m in \u001b[0;36mGenreClassifier.f1_score\u001b[1;34m(self, test_x, test_y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/University%20of%20Malta/BSC%203.1/Deep%20Learning%20for%20NPL/Assignment/movie_titles.ipynb#X26sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/University%20of%20Malta/BSC%203.1/Deep%20Learning%20for%20NPL/Assignment/movie_titles.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(test_x))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/University%20of%20Malta/BSC%203.1/Deep%20Learning%20for%20NPL/Assignment/movie_titles.ipynb#X26sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     f1 \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49mf1_score(test_y, predictions,)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1123\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[0;32m    993\u001b[0m     y_true,\n\u001b[0;32m    994\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1001\u001b[0m ):\n\u001b[0;32m   1002\u001b[0m     \u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \n\u001b[0;32m   1004\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39m    modified with ``zero_division``.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   1124\u001b[0m         y_true,\n\u001b[0;32m   1125\u001b[0m         y_pred,\n\u001b[0;32m   1126\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1127\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1128\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1129\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1130\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1131\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1132\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1261\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[0;32m   1136\u001b[0m     y_true,\n\u001b[0;32m   1137\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1145\u001b[0m ):\n\u001b[0;32m   1146\u001b[0m     \u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \n\u001b[0;32m   1148\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1261\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1262\u001b[0m         y_true,\n\u001b[0;32m   1263\u001b[0m         y_pred,\n\u001b[0;32m   1264\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   1265\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1266\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1267\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1268\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1269\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1270\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1271\u001b[0m     )\n\u001b[0;32m   1272\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1543\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1544\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1546\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1348\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1345\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1346\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1348\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1349\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "classifier.f1_score(indexed_test_x, indexed_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c811f",
   "metadata": {},
   "source": [
    "## Title generation (25%)\n",
    "\n",
    "Now that you've proven that titles and genre are related, make a model that can generate a title given a genre.\n",
    "\n",
    "Again, you need to generate tokens at the character level instead of the word level and the titles must be lowercased.\n",
    "Preprocess the data sets, create a neural network, and train it to generate the movie titles given their genre.\n",
    "Plot a graph of the **perplexity** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36f9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da86299f",
   "metadata": {},
   "source": [
    "Generate 3 titles for every genre.\n",
    "Make sure that the titles are not all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa6465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc97665b",
   "metadata": {},
   "source": [
    "## Language models as classifiers (30%)\n",
    "\n",
    "It occurs to you that the movie title generator can also be used as a classifier by doing the following:\n",
    "\n",
    "* Let title $t$ be the title that you want to classify.\n",
    "* For every genre $g$,\n",
    "    * Use the generator as a language model to get the probability of $t$ (the whole title) using genre $g$.\n",
    "* Pick the genre that makes the language model give the largest probability.\n",
    "\n",
    "The producer is thrilled to not need two separate models and now you have to implement this.\n",
    "**Use the preprocessed test set from the previous task** in order to find the genre that makes the language model give the largest probability.\n",
    "There is no need to plot anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba8fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3841496d",
   "metadata": {},
   "source": [
    "Just like in the classification task, measure the F1 score and plot the confusion matrix of this new classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148060ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6399514",
   "metadata": {},
   "source": [
    "Write a paragraph or psuedo code to describe what your code above does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c9a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5888e6",
   "metadata": {},
   "source": [
    "## Conclusion (10%)\n",
    "\n",
    "The producer's funders are asking for a report about this new technology they invested in.\n",
    "In 300 words, write your interpretation of the results together with what you think could make the model perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3859a0a2c3f08322faa010ffbefd7b0e3ffe116852c95ccecd3e07f499ac40ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
