{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c304f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxma\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Suggested imports. Do not use import any modules that are not in the requirements.txt file on the VLE.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98e8ff",
   "metadata": {},
   "source": [
    "# Movie titles assignment\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "* [Data filtering and splitting (10%)](#Data-filtering-and-splitting-(10%))\n",
    "* [Title classification (25%)](#Title-classification-(25%))\n",
    "* [Title generation (25%)](#Title-generation-(25%))\n",
    "* [Language models as classifiers (30%)](#Language-models-as-classifiers-(30%))\n",
    "* [Conclusion (10%)](#Conclusion-(10%))\n",
    "\n",
    "Information:\n",
    "\n",
    "This assignment is 100% of your assessment.\n",
    "You are to follow the instructions below and fill each cell as instructed.\n",
    "Once ready, submit this notebook on VLE with all the outputs included (run all your code and don't clear any output cells).\n",
    "Do not submit anything else apart from the notebook and do not use any extra data apart from what is requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab5373",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A big shot Hollywood producer is looking for a way to automatically generate new movie titles for future movies and you have been employed to do this (in exchange for millions of dollars!).\n",
    "A data set of movie details has already been collected from IMDb for you and your task is to create the model and the algorithms necessary to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb2f45",
   "metadata": {},
   "source": [
    "## Data filtering and splitting (10%)\n",
    "\n",
    "Start by downloading the CSV file `filmtv_movies - ENG.csv` from [this kaggle data set](https://www.kaggle.com/datasets/stefanoleone992/filmtv-movies-dataset).\n",
    "\n",
    "The CSV file needs to be filtered as the producer is only interested in certain types of movie titles.\n",
    "Load the file and filter it so that only movies with the following criteria are kept:\n",
    "\n",
    "* The country needs to be `United States` (and no other country should be mentioned).\n",
    "* The genre should be `Action`, `Horror`, `Fantasy`, `Western`, and `Adventure`.\n",
    "* The title should not have more than 20 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de60b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/filmtv_movies - ENG.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2a2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['Action', 'Horror', 'Fantasy', 'Western', 'Adventure']\n",
    "\n",
    "data = data.loc[(data['country'] == 'United States') &\n",
    "                (data['genre'].isin(genres)) & \n",
    "                (data['title'].str.len() <= 20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448acbaa",
   "metadata": {},
   "source": [
    "Split the filtered data into 80% train, 10% validation, and 10% test.\n",
    "You will only need the title and genre columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1fca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['title', 'genre']]\n",
    "train, validate, test = np.split(data.sample(frac=1), [int(.8*len(data)), int(.9*len(data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d5332",
   "metadata": {},
   "source": [
    "From your processed data set, display:\n",
    "\n",
    "* the amount of movies in each genre and split\n",
    "* 5 examples of movie titles from each genre and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e8adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 2736\n",
      "Validation Set Size: 342\n",
      "Test Set Size: 342\n",
      "Num. of movies with genre Horror: 926 \n",
      "Num. of movies with genre Action: 914 \n",
      "Num. of movies with genre Western: 538 \n",
      "Num. of movies with genre Adventure: 483 \n",
      "Num. of movies with genre Fantasy: 559 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Set Size: {len(train)}\")\n",
    "print(f\"Validation Set Size: {len(validate)}\")\n",
    "print(f\"Test Set Size: {len(test)}\")\n",
    "\n",
    "for genre in data['genre'].unique():\n",
    "    print(f\"Num. of movies with genre {genre}: {len(data[data['genre'] == genre])} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1240be",
   "metadata": {},
   "source": [
    "## Title classification (25%)\n",
    "\n",
    "Your first task is to prove that a neural network can identify the genre of a movie based on its title.\n",
    "\n",
    "You will note that many titles are just a single word or two words long so you need to work at the character level instead of the word level, that is, a token would be a single character, including punctuation marks and spaces.\n",
    "You must also lowercase the titles.\n",
    "Preprocess the data sets, create a neural network, and train it to classify the movie titles into their genre.\n",
    "Plot a graph of the **accuracy** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7522adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title'] = train['title'].str.lower()\n",
    "titles_temp = train['title'].values\n",
    "titles = [list(title) for title in titles_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e94d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8b60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "train_x = []\n",
    "train_y = []\n",
    "for row in range(0, len(train)):\n",
    "    title = list(train.iloc[row]['title'].lower())\n",
    "    genre = [train.iloc[row]['genre']]\n",
    "\n",
    "    train_x.append(title)\n",
    "    train_y.append(genre)\n",
    "\n",
    "# Testing Set\n",
    "test_x = []\n",
    "test_y = []\n",
    "for row in range(0, len(test)):\n",
    "    title = list(test.iloc[row]['title'].lower())\n",
    "    genre = [test.iloc[row]['genre']]\n",
    "\n",
    "    test_x.append(title)\n",
    "    test_y.append(genre)\n",
    "\n",
    "# Lengths\n",
    "train_lens = torch.tensor(\n",
    "    [len(title) for title in train_x],\n",
    "    dtype=torch.int64, device=device\n",
    ")\n",
    "\n",
    "test_lens = torch.tensor(\n",
    "    [len(title) for title in test_x],\n",
    "    dtype=torch.int64, device=device\n",
    ")\n",
    "\n",
    "max_len = max(max(train_lens), max(test_lens))\n",
    "\n",
    "# Genres\n",
    "genre = sorted(set(genre for text in train_y for genre in text))\n",
    "genre = sorted(genre)\n",
    "\n",
    "# Genre Indexing\n",
    "genre2index = {genre: i for (i, genre) in enumerate(genre)}\n",
    "\n",
    "# vocab\n",
    "frequencies = collections.Counter(letter for text in train_x for word in text for letter in word)\n",
    "vocab = sorted(frequencies.keys(), key=frequencies.get, reverse=True)\n",
    "while frequencies[vocab[-1]] < min_freq:\n",
    "    vocab.pop()\n",
    "vocab = ['<PAD>', '<UNK>'] + sorted(vocab)\n",
    "letter2index = {letter: i for (i, letter) in enumerate(vocab)}\n",
    "\n",
    "# Padding and UNK indexing\n",
    "for i in range(len(train_x)):\n",
    "    for j in range(len(train_x[i])):\n",
    "        if train_x[i][j] not in letter2index:\n",
    "            train_x[i][j] = '<UNK>'\n",
    "    \n",
    "    for x in range(0, (max_len - len(train_x[i]))):\n",
    "        train_x[i].extend(['<PAD>'])\n",
    "    \n",
    "    temp_ans = train_y[i]\n",
    "    train_y[i] = [0] * len(genre)\n",
    "    train_y[i][genre2index[temp_ans[0]]] = 1\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    for j in range(len(test_x[i])):\n",
    "        if test_x[i][j] not in letter2index:\n",
    "            test_x[i][j] = '<UNK>'\n",
    "\n",
    "    for x in range(0, (max_len - len(test_x[i]))):\n",
    "        test_x[i].extend(['<PAD>'])\n",
    "    \n",
    "    temp_ans = test_y[i]\n",
    "    test_y[i] = [0] * len(genre)\n",
    "    test_y[i][genre2index[temp_ans[0]]] = 1\n",
    "\n",
    "# indexing\n",
    "indexed_train_x = torch.tensor([[letter2index[letter] for letter in text] for text in train_x], \n",
    "                                dtype=torch.int64, \n",
    "                                device=device)\n",
    "indexed_train_y = torch.tensor([y for y in train_y],\n",
    "                                dtype=torch.float32, \n",
    "                                device=device)\n",
    "\n",
    "indexed_test_x = torch.tensor([[letter2index[letter] for letter in text] for text in test_x], \n",
    "                                dtype=torch.int64, \n",
    "                                device=device)\n",
    "indexed_test_y = torch.tensor([y for y in test_y],\n",
    "                                dtype=torch.float32, \n",
    "                                device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e49ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 vocab: ['<PAD>', '<UNK>', ' ', '!', '&', \"'\", ',', '-', '.', '/']\n",
      "Last 10 vocab: ['q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Vocab Size: 47\n",
      "\n",
      "First train_x:\n",
      " ['d', 'a', 'r', 'k', ' ', 'a', 'n', 'g', 'e', 'l', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "First train_y: [1, 0, 0, 0, 0]\n",
      "\n",
      "Genres: ['Action', 'Adventure', 'Fantasy', 'Horror', 'Western']\n",
      "\n",
      "First indexed_train_x:\n",
      " tensor([26, 38, 25, 25, 32, 21, 34, 23, 25, 38, 39,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0])\n",
      "First indexed_train_y:\n",
      " tensor([1., 0., 0., 0., 0.])\n",
      "\n",
      "First indexed_test_x:\n",
      " tensor([21, 32, 29, 25, 34,  2, 35, 38, 29, 27, 29, 34,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0])\n",
      "First indexed_test_y:\n",
      " tensor([0., 0., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(f'First 10 vocab: {vocab[:10]}')\n",
    "print(f'Last 10 vocab: {vocab[-10:]}')\n",
    "print(f'Vocab Size: {len(vocab)}\\n')\n",
    "\n",
    "print(f'First train_x:\\n {train_x[1]}\\n')\n",
    "print(f'First train_y: {train_y[0]}\\n')\n",
    "\n",
    "print(f'Genres: {genre}\\n')\n",
    "\n",
    "print(f'First indexed_train_x:\\n {indexed_train_x[0]}')\n",
    "print(f'First indexed_train_y:\\n {indexed_train_y[0]}\\n')\n",
    "\n",
    "print(f'First indexed_test_x:\\n {indexed_test_x[0]}')\n",
    "print(f'First indexed_test_y:\\n {indexed_test_y[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6041f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, chars_size, embedding_size, hidden_size, genre_size, max_len):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = torch.nn.Embedding(chars_size, embedding_size)\n",
    "        self.output_layer = torch.nn.Linear(max_len*hidden_size, genre_size) # Output size number of genres\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden = self.embedding_layer(x)\n",
    "        flattened = torch.flatten(hidden, 1, 2)\n",
    "        return self.output_layer(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "969fec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreClassifier():\n",
    "    \n",
    "    def __init__(self, chars, iters, title_lens, genre_size, embedding, hidden, max_len):\n",
    "        self.model = Model(chars_size=len(chars), embedding_size=embedding, hidden_size=hidden, genre_size=genre_size, max_len=max_len)\n",
    "        self.model.to(device)\n",
    "        self.optimiser = torch.optim.Adam(self.model.parameters())\n",
    "\n",
    "        self.iters = iters\n",
    "        self.title_lens = title_lens\n",
    "        self.train_errors = []\n",
    "    \n",
    "    def run(self, indexed_train_x, indexed_train_y):\n",
    "        print('step', 'error')\n",
    "        self.train_errors = []\n",
    "\n",
    "        for step in range(1, self.iters + 1):  \n",
    "            self.optimiser.zero_grad()\n",
    "            output = self.model(indexed_train_x)\n",
    "            error = torch.nn.functional.binary_cross_entropy_with_logits(output, indexed_train_y)\n",
    "            self.train_errors.append(error.detach().tolist())\n",
    "            error.backward()\n",
    "            self.optimiser.step()\n",
    "\n",
    "            if step%100 == 0:\n",
    "                print(step, self.train_errors[-1])  \n",
    "\n",
    "        \n",
    "        \n",
    "    def accuracy(self, test_x, test_y):\n",
    "        with torch.no_grad():\n",
    "            predictions = torch.sigmoid(self.model(test_x))\n",
    "            accuracy = (torch.round(predictions) == test_y).numpy().mean()\n",
    "            print('Test accuracy: {:.3%}'.format(accuracy))\n",
    "    \n",
    "    def f1_score(self, test_x, test_y):\n",
    "        with torch.no_grad():\n",
    "            predictions = torch.sigmoid(self.model(test_x))\n",
    "            f1 = sklearn.metrics.f1_score(test_y, predictions, average = None)\n",
    "    \n",
    "    def confusion_matrix(self):\n",
    "        predictions = torch.sigmoid(self.model(test_x))\n",
    "        print(predictions)\n",
    "        tn, fp, fn, tpsklearn.metrics.confusion_matrix\n",
    "\n",
    "    def errors(self):\n",
    "        (fig, ax) = plt.subplots(1, 1)\n",
    "        ax.set_xlabel('step')\n",
    "        ax.set_ylabel('$E$')\n",
    "        ax.plot(range(1, len(self.train_errors) + 1), self.train_errors, color='blue', linestyle='-', linewidth=3)\n",
    "        ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7f5db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step error\n",
      "100 0.4399982690811157\n",
      "200 0.4167648255825043\n",
      "300 0.4007088243961334\n",
      "400 0.3878661096096039\n",
      "500 0.37725764513015747\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = GenreClassifier(chars=vocab, iters=500, title_lens=train_lens, genre_size=len(genre), embedding=32, hidden=32, max_len=max_len)\n",
    "classifier.run(indexed_train_x, indexed_train_y)\n",
    "classifier.errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cb755a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 77.193%\n"
     ]
    }
   ],
   "source": [
    "classifier.accuracy(indexed_test_x, indexed_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53265d7",
   "metadata": {},
   "source": [
    "Measure the F1 score performance of the model when applied on the test set.\n",
    "Also plot a confusion matrix showing how often each genre is mistaken as another genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3e9f69c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3376\\3736998241.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexed_test_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexed_test_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3376\\2979285975.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(self, test_x, test_y)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxma\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m         \u001b[0mzero_division\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m     )\n\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxma\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1268\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"f-score\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1270\u001b[1;33m         \u001b[0mzero_division\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1271\u001b[0m     )\n\u001b[0;32m   1272\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxma\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxma\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxma\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     93\u001b[0m         raise ValueError(\n\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             )\n\u001b[0;32m     97\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "classifier.f1_score(indexed_test_x, indexed_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c811f",
   "metadata": {},
   "source": [
    "## Title generation (25%)\n",
    "\n",
    "Now that you've proven that titles and genre are related, make a model that can generate a title given a genre.\n",
    "\n",
    "Again, you need to generate tokens at the character level instead of the word level and the titles must be lowercased.\n",
    "Preprocess the data sets, create a neural network, and train it to generate the movie titles given their genre.\n",
    "Plot a graph of the **perplexity** of the model on the train and validation sets after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36f9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da86299f",
   "metadata": {},
   "source": [
    "Generate 3 titles for every genre.\n",
    "Make sure that the titles are not all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa6465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc97665b",
   "metadata": {},
   "source": [
    "## Language models as classifiers (30%)\n",
    "\n",
    "It occurs to you that the movie title generator can also be used as a classifier by doing the following:\n",
    "\n",
    "* Let title $t$ be the title that you want to classify.\n",
    "* For every genre $g$,\n",
    "    * Use the generator as a language model to get the probability of $t$ (the whole title) using genre $g$.\n",
    "* Pick the genre that makes the language model give the largest probability.\n",
    "\n",
    "The producer is thrilled to not need two separate models and now you have to implement this.\n",
    "**Use the preprocessed test set from the previous task** in order to find the genre that makes the language model give the largest probability.\n",
    "There is no need to plot anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba8fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3841496d",
   "metadata": {},
   "source": [
    "Just like in the classification task, measure the F1 score and plot the confusion matrix of this new classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148060ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6399514",
   "metadata": {},
   "source": [
    "Write a paragraph or psuedo code to describe what your code above does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c9a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5888e6",
   "metadata": {},
   "source": [
    "## Conclusion (10%)\n",
    "\n",
    "The producer's funders are asking for a report about this new technology they invested in.\n",
    "In 300 words, write your interpretation of the results together with what you think could make the model perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba52e550df5dd7c4d4156f043c0b54db698368195948b3b2935474e916126db8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
